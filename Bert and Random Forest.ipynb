{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed47f18-d782-476c-9812-e48f9dfd630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea87596-ec21-49a0-829d-4c487f7f9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pypdf import PdfReader # Read pdf\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a137b4f2-1292-45db-9811-9e7c81983d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dabbb98e-c5d5-4055-a19b-19f6944325bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32f26cf-2df9-4e6c-92c1-d6e802adcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_read(url):\n",
    "    reader = PdfReader(url)\n",
    "    read = reader.pages[0]\n",
    "    text = read.extract_text()\n",
    "    return text\n",
    "\n",
    "url = './resume.pdf'\n",
    "resume = pdf_read(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68bd397-50a2-4df2-85e7-bc80a253e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./job.txt', 'r', encoding='utf-8') as file:\n",
    "    job = file.readlines()  # Returns a list of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5798b49-3713-4beb-b39f-922284950e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)  \n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88488914-1efb-479f-9201-bde1a3d5df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = cleanResume(str(resume))\n",
    "job = cleanResume(str(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d32f5c44-9eec-4336-9624-87e344359099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ali Hassan 26 Awami Colony Ghazi Road Lahore 92 03048630925 linkedin com in alihassanml github com alihassanml kaggle com alihassanml alihassanml vercel app alihassanbscs99 EDUCATI ON COLLE GE UNIVER SITY Graduation year Defence Degree College Lahore Grade A from 2020 22 Lahore Garrison University from 2022 26 PRO FE SSION AL E XP ERIE NCE Professional Summary Experienced Machine Learning Engineer and Data Scientist specializing in Deep Learning predictive modeling and data analysis using Python TensorFlow and Keras Proficient Full Stack Web Developer with expertise in React Flask FastAPI and one month of experience with Django Extensive project experience at a local software house Currently exploring Generative AI and Langchain passionate about innovation and continuous learning Skilled at transforming complex data into actionable strategies and optimizing web applications Committed to leveraging technology to solve complex problems and drive positive business impacts Freelance Machine Learning Engineer from 02 June to 5 July 2024 Location Lahore Pakistan Developed a Skill Finder application that utilizes machine learning to analyze resumes and match them with job descriptions based on required skills The project was built using a Python based machine learning model deployed with Flask for the backend API and integrated with a React frontend for a seamless user experience DataHorse Machine Learning Engineer From 20 Aug to 7 Sept 2024 Location Lahore Pakistan Developed an advanced data analysis tool at DataHorse using a large language model LLM Implemented a Streamlit app that leverages Groq API for generating Python code to process and analyze data improving efficiency in handling and visualizing datasets PROJE CTS E XTRACURRICUL AR Face mask detection From 2 Feb to 3 Mar 2024 This project is a Streamlit web application that detects whether a person is wearing a face mask using a Convolutional Neural Network CNN The application offers three options for input uploading an image entering an image URL or capturing a live image using a webcam Github Link Face Recognition Attendance System March 02 2024 This project uses FastAPI to deploy an attendance system integrated with face recognition It captures live video from a webcam detects faces matches them with a pre defined list of known faces and mark attendance a ordingly Github Link Langchian Gemini QuizGenius Application March 02 2024 QuizGenius is an interactive Multiple Choice Questions MCQ application powered by LangChain Streamlit and Gemini It allows users to generate and answer MCQs on various topics providing immediate feedback and performance rewards Github Link SKILL S Programming languages Html CSS Java Script Python C SQL Computer software frameworks Django Flask FastApi Computer Vision OpenCV Tensorflow Streamlit MLflow NLP LangChain Docke scikit learn Keras React Vite Seaborn Matplotlib Pandas Mlops Githib \n",
      "\n",
      "Job :  Job Title Data Scientist n Location Remote On site Karachi Pakistan n Company TechNova Analytics n Job Type Full Time n n About the Role n We re looking for a passionate and analytical Data Scientist to join our growing analytics team You will play a key role in transforming raw data into actionable insights to support business decision making and strategy development n n Requirements n Education n Bachelor s degree BS in Computer Science Data Science Statistics Mathematics or a related field n Experience n 2 years of experience working in a data science or analytics role n Skills n Proficiency in Python and SQL n Experience with machine learning libraries such as Scikit learn TensorFlow or PyTorch n Strong knowledge of statistical analysis and data visualization tools e g Tableau Power BI or Matplotlib n Familiarity with cloud platforms AWS GCP or Azure n Experience with big data tools like Spark or Hadoop is a plus n Solid understanding of data preprocessing and feature engineering n n Key Responsibilities n Analyze large datasets to discover trends and patterns n Build predictive models and machine learning algorithms n Collaborate with cross functional teams to understand business objectives n Develop data visualization dashboards to present insights n Ensure data integrity and improve data collection strategies n n Benefits n Competitive salary n Flexible working hours n Health insurance n Learning and development opportunities n Annual performance bonuses n \n"
     ]
    }
   ],
   "source": [
    "print(resume)\n",
    "print(f'\\nJob : {job}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35048632-0376-4c84-8a8b-8fd31748d952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7efad8f3-86ef-440a-a4ec-abd64ec54094",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vector = text_to_vector(resume)\n",
    "job_vector = text_to_vector(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93bd377b-de09-447e-b819-070769c1a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169909c6-2f61-4572-95c6-8e2db8a9c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = ResumeParser(url).get_extracted_data()\n",
    "print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94d9f1-e0d7-4381-9f9b-a659ff3531f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50df9b69-4a4b-4023-ae79-ab2e1ae1afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score: 0.6069455146789551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_score = cosine_similarity([resume_vector], [job_vector])[0][0]\n",
    "print(f\"Matching Score: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f2dcb67-fdef-478c-a7f8-324c84b40651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([resume_vector, job_vector])  # Feature vectors\n",
    "y_train = np.array([1, 0])  # Labels (1 = Match, 0 = No Match)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict([resume_vector])\n",
    "print(\"Match\" if prediction[0] == 1 else \"No Match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7e925-7ef5-4bd9-89d6-439998d15688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
